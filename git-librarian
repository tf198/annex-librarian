#!/usr/bin/env python2.7

import argparse
import sys
import logging
import os.path
import json

from librarian import Librarian

logger = logging.getLogger(__name__)

def run_sync(l, options):
    return l.sync(options.commit, options.fresh)

def run_search(l, options):

    pagesize = l.db.db.get_doccount() if options.all else options.limit
    offset = 0 if options.all else options.offset

    result = l.search(" ".join(options.terms), offset, pagesize)

    if options.json:
        for r in result['matches']:
            sys.stdout.write(json.dumps(r))
            sys.stdout.write("\n")
        return

    # need to map everything back to current branch
    with open(l.relative_path('.git/HEAD'), 'r') as f:
        raw = f.read()
        branch = os.path.basename(raw.strip())
    sys.stderr.write("Current branch: %s\n" % branch)

    filtered = 0
    for r in result['matches']:
        data = l.get_data(r['key'])
        p = data.get('paths', {}).get(branch)
        if p is None:
            filtered += 1
        else:
            sys.stdout.write("%s\n" % p)

    sys.stderr.write("Results {0:d} to {1:d} of {2:d} ({3:d} filtered)\n".format(result['start'], result['end'], result['total'], filtered))

def run_server(l, options):
    from librarian.api import create_api
    from flask import Flask, send_from_directory, redirect
    from gevent.wsgi import WSGIServer
    from librarian.watcher import FileWatcher

    api = create_api(l)

    app = Flask(__name__)
    app.register_blueprint(api, url_prefix='/api')

    here = os.path.dirname(os.path.realpath(__file__))
    logger.info("Serving static files from %s", here);

    @app.route('/public/<path:path>')
    @app.route('/public/', defaults={'path': 'index.html'})
    def static_files(path):
        return send_from_directory(os.path.join(here, 'public'), path)

    @app.route('/')
    def redirect_home():
        return redirect('/public/')

    w = FileWatcher(l.relative_path('.git/refs/heads/git-annex'), l.sync)
    w.start()
    
    sys.stderr.write("Listening on %d\n" % options.port)
    WSGIServer(('', options.port), app).serve_forever()

def run_show(l, options):
    detail = l.get_details(options.file, options.terms)
    return json.dumps(detail, indent=1)

def run_inspector(l, options):
    from librarian.inspectors import Inspector 

    inspector = Inspector('file', 'image')

    if options.files:
        result = inspector.inspect_items(l.annex, options.files, options.keys)
        result['commit'] = l.sync()
    else:
        result = {'inspected': 0, 'total': 0}
        c = 0
        total = 0
        while True:
            items = l.search('state:noinfo', pagesize=options.batch)['matches']

            if len(items) == 0:
                break

            result['total'] += len(items)

            r = inspector.inspect_items(l.annex, [ x['key'] for x in items ], True)
            result['inspected'] += r['inspected']
            result['commit'] = l.sync()

            if options.limit and result.total > options.limit:
                break

    return "Inspected {inspected} of {total} files".format(**result)

parser = argparse.ArgumentParser(description="Curator for your annexed data")

parser.add_argument('-C', default='.', dest="path", 
        help="Run as if git was started in <PATH>")
parser.add_argument('-l', dest="logging",
        help="Logging string (format: name:level, default: none)")
parser.add_argument('-q', '--quiet', action="store_true",
        help="Dont output progress")

subparsers = parser.add_subparsers();

sync_cmd = subparsers.add_parser('sync', help="Synchronize library",
        description="Read all new commits and index data")
sync_cmd.add_argument('-c', '--commit', help="From commit")
sync_cmd.add_argument('-f', '--fresh', action="store_true", default=False, 
        help="Clear current database and start from scratch")
sync_cmd.set_defaults(func=run_sync)

search_cmd = subparsers.add_parser('search', help="Search library",
        description="Output a list keys which match the search terms")
search_cmd.add_argument('terms', nargs="+",
        help="Search terms")
search_cmd.add_argument('-o', '--offset', type=int, default=0,
        help="Offset results")
search_cmd.add_argument('-l', '--limit', type=int, default=20,
        help="Limit results")
search_cmd.add_argument('-a', '--all', action="store_true",
        help="Return all matches (warning - could be a lot!)")
search_cmd.add_argument('--json', action="store_true",
        help="Output one JSON object per line with key, date and rank properties")
search_cmd.set_defaults(func=run_search)

server_cmd = subparsers.add_parser('server', help="Run api server")
server_cmd.add_argument('-p', '--port', type=int, default=7920,
        help="Port to use")
server_cmd.set_defaults(func=run_server)

show_cmd = subparsers.add_parser('show', help="Show information for a document",
        description="Show information for a document")
show_cmd.add_argument('-t', '--terms', action="store_true",
        help="Show stored terms")
show_cmd.add_argument('file', help="File to show")
show_cmd.set_defaults(func=run_show)

inspect_cmd = subparsers.add_parser('inspect', help="Run inspectors on one or more documents",
        description="Run all configured inspectors on the files specified")
inspect_cmd.add_argument('-k', '--keys', help="Items are keys, not files")
inspect_cmd.add_argument('-i', '--inspector', default="auto", help="Use a specific extractor")
inspect_cmd.add_argument('-b', '--batch', type=int, default=100)
inspect_cmd.add_argument('-l', '--limit', type=int, default=0)
inspect_cmd.add_argument('files', nargs="*" ,help="Files to inspect")
inspect_cmd.set_defaults(func=run_inspector)

args = parser.parse_args()

if not hasattr(args, 'func'):
    parser.print_help()
    exit(1)

if args.logging:
    log = args.logging.split(':')
    if len(log) == 1: log.append('INFO')

    target = logging.getLogger(log[0])
    target.setLevel(getattr(logging, log[1].upper(), logging.INFO))

    console = logging.StreamHandler(sys.stderr)
    console.setFormatter(logging.Formatter("%(levelname)5s: %(message)s"))
    target.addHandler(console)
else:
    logging.basicConfig(level=logging.WARNING)

logger = logging.getLogger(__name__)
logger.debug("Args: %r", args)

try:
    l = Librarian(args.path)
    result = args.func(l, args)
    if result:
        sys.stdout.write(result)
        sys.stdout.write("\n")
except Exception as e:
    sys.stderr.write("Error: {0}\n".format(e))
    logging.exception(e)
    exit(1)
